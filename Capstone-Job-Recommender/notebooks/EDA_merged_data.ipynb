{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6adee5",
   "metadata": {},
   "source": [
    "Schema-unification & dataset merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8496a",
   "metadata": {},
   "source": [
    "Building a unified schema for merging all existing datasets for furter EDA & feature engineering.\n",
    "- It maps each dataset to a common schema, fills string nulls with \"N/A\", keeps numerics as real NaNs, and saves a single merged file.\n",
    "\n",
    "What this does:\n",
    "- Reads your already-deduped CSVs from prepared/ (no extra file finding).\n",
    "- Maps each dataset to the unified columns (no country, no source).\n",
    "- Trims and normalizes text, fills string nulls with \"N/A\"; numeric salary_numeric stays NaN.\n",
    "- Concatenates all three into jobs_merged_unified.csv under prepared/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9ffd72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified shape: (40774, 13)\n",
      "Columns: ['job_title', 'role', 'company', 'location', 'employment_type', 'skills', 'job_description', 'responsibilities', 'qualifications', 'experience', 'salary', 'salary_numeric', 'post_date']\n",
      "\n",
      "Row counts by source chunk (for reference):\n",
      "Morocco: 345 | Dice: 20598 | SriLanka: 19831\n",
      "\n",
      "Saved merged dataset â†’ processed /jobs_merged_unified.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "%run ./hidden.ipynb\n",
    "\n",
    "# ----------------------------\n",
    "# Paths (all from prepared/)\n",
    "# ----------------------------\n",
    "p_mr = datasets_folder_path / \"prepared\" / \"morocco_deduped.csv\"\n",
    "p_dc = datasets_folder_path / \"prepared\" / \"dice_com_deduped.csv\"\n",
    "p_sl = datasets_folder_path / \"prepared\" / \"srilanka_deduped.csv\"\n",
    "\n",
    "# ----------------------------\n",
    "# Unified schema (no country, no source)\n",
    "# ----------------------------\n",
    "UNIFIED_COLS = [\n",
    "    \"job_title\",\n",
    "    \"role\",\n",
    "    \"company\",\n",
    "    \"location\",\n",
    "    \"employment_type\",\n",
    "    \"skills\",\n",
    "    \"job_description\",\n",
    "    \"responsibilities\",\n",
    "    \"qualifications\",\n",
    "    \"experience\",\n",
    "    \"salary\",          # textual range if present\n",
    "    \"salary_numeric\",  # numeric if present\n",
    "    \"post_date\"\n",
    "]\n",
    "\n",
    "def _strip_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Trim whitespace in all object columns.\"\"\"\n",
    "    for c in df.select_dtypes(include=\"object\").columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "        # Normalize empty/placeholder to NaN (so we can fill consistently later)\n",
    "        df.loc[df[c].isin([\"\", \"nan\", \"None\", \"N/A\", \"NA\", \"NaN\"]), c] = pd.NA\n",
    "    return df\n",
    "\n",
    "def _finalize_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Fill missing string columns with 'N/A' (leave numerics as NaN).\"\"\"\n",
    "    obj_cols = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "    df[obj_cols] = df[obj_cols].fillna(\"N/A\")\n",
    "    return df\n",
    "\n",
    "# ----------------------------\n",
    "# Morocco mapping â†’ unified\n",
    "# ----------------------------\n",
    "def load_morocco_unified(path: str | Path): \n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    # Expected columns (already deduped and pruned earlier)\n",
    "    # ['Experience','Qualifications','Salary Range','location','Work Type',\n",
    "    #  'Job Title','Role','Job Description','skills','Responsibilities',\n",
    "    #  'Company','Salary_Numeric']\n",
    "    out = pd.DataFrame({\n",
    "        \"job_title\":       df.get(\"Job Title\"),\n",
    "        \"role\":            df.get(\"Role\"),\n",
    "        \"company\":         df.get(\"Company\"),\n",
    "        \"location\":        df.get(\"location\"),\n",
    "        \"employment_type\": df.get(\"Work Type\"),\n",
    "        \"skills\":          df.get(\"skills\"),\n",
    "        \"job_description\": df.get(\"Job Description\"),\n",
    "        \"responsibilities\":df.get(\"Responsibilities\"),\n",
    "        \"qualifications\":  df.get(\"Qualifications\"),\n",
    "        \"experience\":      df.get(\"Experience\"),\n",
    "        \"salary\":          df.get(\"Salary Range\"),\n",
    "        \"salary_numeric\":  pd.to_numeric(df.get(\"Salary_Numeric\"), errors=\"coerce\"),\n",
    "        \"post_date\":       pd.NA,  # not useful/available\n",
    "    })\n",
    "    out = _strip_strings(out)\n",
    "    # Ensure correct column order\n",
    "    return out.reindex(columns=UNIFIED_COLS)\n",
    "\n",
    "# ----------------------------\n",
    "# Dice.com mapping â†’ unified\n",
    "# ----------------------------\n",
    "def load_dice_unified(path: str | Path):\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    # Expected columns:\n",
    "    # ['company','employmenttype_jobstatus','jobdescription',\n",
    "    #  'joblocation_address','jobtitle','postdate','skills']\n",
    "    out = pd.DataFrame({\n",
    "        \"job_title\":       df.get(\"jobtitle\"),\n",
    "        \"role\":            pd.NA,  # not present\n",
    "        \"company\":         df.get(\"company\"),\n",
    "        \"location\":        df.get(\"joblocation_address\"),\n",
    "        \"employment_type\": df.get(\"employmenttype_jobstatus\"),\n",
    "        \"skills\":          df.get(\"skills\"),\n",
    "        \"job_description\": df.get(\"jobdescription\"),\n",
    "        \"responsibilities\":pd.NA,\n",
    "        \"qualifications\":  pd.NA,\n",
    "        \"experience\":      pd.NA,\n",
    "        \"salary\":          pd.NA,\n",
    "        \"salary_numeric\":  pd.Series([np.nan] * len(df), dtype=\"float64\"),  # Use np.nan instead of pd.NA\n",
    "        \"post_date\":       df.get(\"postdate\"),\n",
    "    })\n",
    "    out = _strip_strings(out)\n",
    "    return out.reindex(columns=UNIFIED_COLS)\n",
    "\n",
    "# ----------------------------\n",
    "# Sri Lanka mapping â†’ unified\n",
    "# ----------------------------\n",
    "def load_srilanka_unified(path: str | Path):\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    # Expected columns:\n",
    "    # ['Job Role','Job Title','Student Qualification','Student Skills','Job Description']\n",
    "    out = pd.DataFrame({\n",
    "        \"job_title\":       df.get(\"Job Title\"),\n",
    "        \"role\":            df.get(\"Job Role\"),\n",
    "        \"company\":         pd.NA,\n",
    "        \"location\":        pd.NA,  # country dropped; location not present\n",
    "        \"employment_type\": pd.NA,\n",
    "        \"skills\":          df.get(\"Student Skills\"),\n",
    "        \"job_description\": df.get(\"Job Description\"),\n",
    "        \"responsibilities\":pd.NA,\n",
    "        \"qualifications\":  df.get(\"Student Qualification\"),\n",
    "        \"experience\":      pd.NA,\n",
    "        \"salary\":          pd.NA,\n",
    "        \"salary_numeric\":  pd.Series(np.nan, index=df.index, dtype=\"float64\"),\n",
    "        \"post_date\":       pd.NA,\n",
    "    })\n",
    "    out = _strip_strings(out)\n",
    "    return out.reindex(columns=UNIFIED_COLS)\n",
    "\n",
    "# ----------------------------\n",
    "# Load each â†’ concat â†’ finalize\n",
    "# ----------------------------\n",
    "df_mr = load_morocco_unified(p_mr)\n",
    "df_dc = load_dice_unified(p_dc)\n",
    "df_sl = load_srilanka_unified(p_sl)\n",
    "\n",
    "# Merge\n",
    "df_all = pd.concat([df_mr, df_dc, df_sl], ignore_index=True)\n",
    "\n",
    "# Fill strings with \"N/A\" (numeric stays NaN)\n",
    "df_all = _finalize_strings(df_all)\n",
    "\n",
    "# Optional: collapse multiple internal spaces & standardize commas in skills/location\n",
    "def _normalize_commas(s):\n",
    "    if pd.isna(s): return s\n",
    "    s = \" \".join(str(s).split())        # collapse whitespace\n",
    "    s = s.replace(\" ,\", \",\").replace(\", \", \", \").replace(\" , \", \", \")\n",
    "    return s\n",
    "\n",
    "for col in [\"skills\", \"location\"]:\n",
    "    if col in df_all.columns:\n",
    "        df_all[col] = df_all[col].map(_normalize_commas)\n",
    "\n",
    "print(\"Unified shape:\", df_all.shape)\n",
    "print(\"Columns:\", df_all.columns.tolist())\n",
    "print(\"\\nRow counts by source chunk (for reference):\")\n",
    "print(\"Morocco:\", len(df_mr), \"| Dice:\", len(df_dc), \"| SriLanka:\", len(df_sl))\n",
    "\n",
    "# ----------------------------\n",
    "# Save unified merged dataset\n",
    "# ----------------------------\n",
    "out_path = datasets_folder_path / \"processed\" / \"jobs_merged_unified.csv\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_all.to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved merged dataset â†’ processed /jobs_merged_unified.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910a450",
   "metadata": {},
   "source": [
    "ðŸ“Š Post-Merge Quick Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf488be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unified Dataset Summary ===\n",
      "Shape: (40774, 13)\n",
      "\n",
      "% of 'N/A' values per column:\n",
      "employment_type     0.5\n",
      "company             0.1\n",
      "skills              0.1\n",
      "role                0.0\n",
      "job_title           0.0\n",
      "location            0.0\n",
      "job_description     0.0\n",
      "responsibilities    0.0\n",
      "qualifications      0.0\n",
      "experience          0.0\n",
      "salary              0.0\n",
      "salary_numeric      0.0\n",
      "post_date           0.0\n",
      "\n",
      "Top 10 Job Titles:\n",
      "job_title\n",
      "Cloud Infrastructure Engineer    1046\n",
      "Information Security Analyst     1032\n",
      "AI Engineer                      1023\n",
      "System Analyst                   1008\n",
      "SOC Analyst                      1001\n",
      "CI/CD Engineer                    995\n",
      "Help Desk Technician              982\n",
      "Technical Support Engineer        980\n",
      "IT Business Analyst               971\n",
      "NLP Engineer                      961\n",
      "\n",
      "Employment Type Distribution:\n",
      "employment_type\n",
      "<NA>                                                                                                   19831\n",
      "Full Time                                                                                               6264\n",
      "Contract W2                                                                                             1034\n",
      "Contract Corp-To-Corp, Contract Independent, Contract W2                                                 593\n",
      "Full Time, Full Time                                                                                     591\n",
      "Contract Corp-To-Corp, Contract Independent, Contract W2, C2H Corp-To-Corp, C2H Independent, C2H W2      450\n",
      "Full Time, Permanent                                                                                     343\n",
      "Full Time, Full-time, Employee                                                                           321\n",
      "C2H W2                                                                                                   282\n",
      "Contract Corp-To-Corp                                                                                    254\n",
      "\n",
      "Top 10 Companies:\n",
      "company\n",
      "<NA>                        19831\n",
      "CyberCoders                   325\n",
      "Amazon                        250\n",
      "Robert Half Technology        245\n",
      "Robert Half                   214\n",
      "Collabera                     166\n",
      "U.S. Tech Solutions Inc.      163\n",
      "Kforce Inc.                   161\n",
      "The Judge Group               157\n",
      "Visionaire Partners           156\n",
      "\n",
      "Salary Numeric (ignoring NaNs):\n",
      "count       345.000000\n",
      "mean     140019.498551\n",
      "std       40048.567758\n",
      "min       57656.000000\n",
      "25%      110702.000000\n",
      "50%      135222.000000\n",
      "75%      167853.000000\n",
      "max      249555.000000\n",
      "Name: salary_numeric, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Quick post-merge summary ---\n",
    "\n",
    "print(\"=== Unified Dataset Summary ===\")\n",
    "print(\"Shape:\", df_all.shape)\n",
    "\n",
    "# % of N/A per column\n",
    "na_pct = (df_all == \"N/A\").mean().round(3) * 100\n",
    "print(\"\\n% of 'N/A' values per column:\")\n",
    "print(na_pct.sort_values(ascending=False).to_string())\n",
    "\n",
    "# Top 10 job titles\n",
    "print(\"\\nTop 10 Job Titles:\")\n",
    "print(df_all['job_title'].value_counts().head(10).to_string())\n",
    "\n",
    "# Top 10 employment types\n",
    "if \"employment_type\" in df_all.columns:\n",
    "    print(\"\\nEmployment Type Distribution:\")\n",
    "    print(df_all['employment_type'].value_counts().head(10).to_string())\n",
    "\n",
    "# Top 10 companies (non-N/A)\n",
    "print(\"\\nTop 10 Companies:\")\n",
    "print(df_all.loc[df_all['company'] != \"N/A\", 'company'].value_counts().head(10).to_string())\n",
    "\n",
    "# Salary summary (numeric only)\n",
    "if \"salary_numeric\" in df_all.columns:\n",
    "    print(\"\\nSalary Numeric (ignoring NaNs):\")\n",
    "    print(df_all['salary_numeric'].describe(percentiles=[.25,.5,.75]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
