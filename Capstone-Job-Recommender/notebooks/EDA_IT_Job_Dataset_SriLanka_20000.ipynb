{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016d43d5",
   "metadata": {},
   "source": [
    "üîé Step 1 ‚Äî Load & basic inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484f30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (20000, 5)\n",
      "Columns: ['Job Role', 'Job Title', 'Student Qualification', 'Student Skills', 'Job Description']\n",
      "\n",
      "Data types:\n",
      " Job Role                 object\n",
      "Job Title                object\n",
      "Student Qualification    object\n",
      "Student Skills           object\n",
      "Job Description          object\n",
      "dtype: object\n",
      "\n",
      "=== Missingness summary ===\n",
      "                       num_missing  pct_missing\n",
      "Job Role                         0          0.0\n",
      "Job Title                        0          0.0\n",
      "Student Qualification            0          0.0\n",
      "Student Skills                   0          0.0\n",
      "Job Description                  0          0.0\n",
      "\n",
      "Fully duplicated rows: 31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "%run ./hidden.ipynb\n",
    "\n",
    "# Load Sri Lanka dataset\n",
    "df_sl = pd.read_csv(datasets_folder_path/\"raw/IT_Job_Dataset_SriLanka_20000 (1).csv\", low_memory=False)\n",
    "\n",
    "print(\"Shape:\", df_sl.shape)\n",
    "print(\"Columns:\", df_sl.columns.tolist())\n",
    "print(\"\\nData types:\\n\", df_sl.dtypes)\n",
    "\n",
    "# Missingness summary\n",
    "missing_summary_sl = (\n",
    "    df_sl.isna()\n",
    "         .sum()\n",
    "         .to_frame(\"num_missing\")\n",
    "         .assign(pct_missing=lambda x: (x[\"num_missing\"]/len(df_sl)).round(4))\n",
    "         .sort_values(\"pct_missing\", ascending=False)\n",
    ")\n",
    "print(\"\\n=== Missingness summary ===\")\n",
    "print(missing_summary_sl.to_string())\n",
    "\n",
    "# Fully duplicated rows\n",
    "num_dups_full = df_sl.duplicated().sum()\n",
    "print(\"\\nFully duplicated rows:\", num_dups_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa335cc",
   "metadata": {},
   "source": [
    "üîé Step 2.1 ‚Äî Unique value distributions\n",
    "\n",
    "For useful categoricals in Sri Lanka dataset:\n",
    "- Job Title\n",
    "- Job Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e8a18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Job Title ===\n",
      "Unique categories: 25\n",
      "\n",
      "Top 20 frequencies:\n",
      "Job Title\n",
      "Cloud Infrastructure Engineer    1053\n",
      "AI Engineer                      1040\n",
      "Information Security Analyst     1028\n",
      "System Analyst                   1009\n",
      "SOC Analyst                      1008\n",
      "CI/CD Engineer                   1006\n",
      "Help Desk Technician              989\n",
      "Technical Support Engineer        986\n",
      "IT Business Analyst               976\n",
      "NLP Engineer                      970\n",
      "Full Stack Engineer               726\n",
      "Data Visualization Expert         721\n",
      "Business Intelligence Analyst     693\n",
      "Android Developer                 686\n",
      "System Administrator              682\n",
      "React Developer                   670\n",
      "Flutter Developer                 659\n",
      "UI Developer                      658\n",
      "Frontend Developer                658\n",
      "iOS Developer                     657\n",
      "\n",
      "Singleton categories (appear once): 0\n",
      "\n",
      "=== Job Role ===\n",
      "Unique categories: 10\n",
      "\n",
      "Top 20 frequencies:\n",
      "Job Role\n",
      "DevOps Engineer              2059\n",
      "Data Analyst                 2052\n",
      "Cybersecurity Analyst        2036\n",
      "Machine Learning Engineer    2010\n",
      "Mobile App Developer         2002\n",
      "Software Engineer            1998\n",
      "Business Analyst             1985\n",
      "IT Support Specialist        1975\n",
      "Web Developer                1973\n",
      "Network Administrator        1910\n",
      "\n",
      "Singleton categories (appear once): 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2.1 ‚Äî Unique distributions\n",
    "target_cols = [\"Job Title\", \"Job Role\"]\n",
    "\n",
    "for col in target_cols:\n",
    "    if col not in df_sl.columns:\n",
    "        continue\n",
    "    s = df_sl[col].astype(str).str.strip()\n",
    "    n_unique = s.nunique(dropna=True)\n",
    "    print(f\"\\n=== {col} ===\")\n",
    "    print(f\"Unique categories: {n_unique}\")\n",
    "    \n",
    "    vc = s.value_counts(dropna=False)\n",
    "    print(\"\\nTop 20 frequencies:\")\n",
    "    print(vc.head(20).to_string())\n",
    "    print(f\"\\nSingleton categories (appear once): {(vc == 1).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f42bb",
   "metadata": {},
   "source": [
    "üîé Step 2.2 ‚Äî Duplicate check (signal columns)\n",
    "\n",
    "Here, the most important ‚Äúsignal‚Äù columns are:\n",
    "['Job Role', 'Job Title', 'Student Skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc63778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Duplicate Analysis (Job Role, Job Title, Student Skills) ===\n",
      "Total rows: 20000\n",
      "Duplicate rows (same triplet): 334\n",
      "Rows after dropping duplicates: 19831\n",
      "Percent rows removed by collapsing: 0.84%\n"
     ]
    }
   ],
   "source": [
    "# Step 2.2 ‚Äî Duplicates on signal columns\n",
    "signal_cols_sl = [\"Job Role\", \"Job Title\", \"Student Skills\"]\n",
    "\n",
    "missing = [c for c in signal_cols_sl if c not in df_sl.columns]\n",
    "if missing:\n",
    "    print(f\"[WARN] Missing signal columns: {missing}\")\n",
    "else:\n",
    "    dup_mask = df_sl.duplicated(subset=signal_cols_sl, keep=False)\n",
    "    num_dup_rows = dup_mask.sum()\n",
    "    collapsed_rows = len(df_sl) - df_sl.duplicated(subset=signal_cols_sl, keep=\"first\").sum()\n",
    "    collapsed_pct = round(100 * (len(df_sl) - collapsed_rows) / len(df_sl), 2)\n",
    "    \n",
    "    print(\"\\n=== Duplicate Analysis (Job Role, Job Title, Student Skills) ===\")\n",
    "    print(f\"Total rows: {len(df_sl)}\")\n",
    "    print(f\"Duplicate rows (same triplet): {num_dup_rows}\")\n",
    "    print(f\"Rows after dropping duplicates: {collapsed_rows}\")\n",
    "    print(f\"Percent rows removed by collapsing: {collapsed_pct}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f34135",
   "metadata": {},
   "source": [
    "üîé Step 2.3 ‚Äî Text length sanity\n",
    "\n",
    "Columns worth checking: Student Skills, Job Description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae849c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Text Column Length Stats (Sri Lanka) ===\n",
      "                 num_rows  num_missing  num_empty  min_len  max_len  mean_len  median_len  pct_empty\n",
      "Student Skills    20000.0          0.0        0.0     12.0     58.0  31.75085        32.0        0.0\n",
      "Job Description   20000.0          0.0        0.0     59.0     77.0  68.89020        70.0        0.0\n"
     ]
    }
   ],
   "source": [
    "# Step 2.3 ‚Äî Text length stats\n",
    "text_cols_sl = [\"Student Skills\", \"Job Description\"]\n",
    "\n",
    "def text_len_report(frame, cols):\n",
    "    out = {}\n",
    "    for col in cols:\n",
    "        s = frame[col].astype(str).fillna(\"\")\n",
    "        lens = s.str.len()\n",
    "        out[col] = {\n",
    "            \"num_rows\": len(s),\n",
    "            \"num_missing\": frame[col].isna().sum(),\n",
    "            \"num_empty\": int((s.eq(\"\") | s.str.strip().eq(\"\")).sum()),\n",
    "            \"min_len\": int(lens.min()),\n",
    "            \"max_len\": int(lens.max()),\n",
    "            \"mean_len\": float(lens.mean()),\n",
    "            \"median_len\": float(lens.median()),\n",
    "            \"pct_empty\": round(100 * (s.eq(\"\") | s.str.strip().eq(\"\")).mean(), 2),\n",
    "        }\n",
    "    return pd.DataFrame(out).T.sort_values(\"pct_empty\", ascending=False)\n",
    "\n",
    "text_stats_sl = text_len_report(df_sl, text_cols_sl)\n",
    "print(\"\\n=== Text Column Length Stats (Sri Lanka) ===\")\n",
    "print(text_stats_sl.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940acc3a",
   "metadata": {},
   "source": [
    "Saving Cleaned Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a2dfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (20000, 5)\n",
      "Duplicates shape: (334, 5)\n",
      "Deduped shape: (19831, 5)\n",
      "Files saved in 'processed' folder:\n",
      "- srilanka_duplicates.csv (only duplicate rows)\n",
      "- srilanka_deduped.csv (original minus duplicates)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "signal_cols_sl = [\"Job Role\", \"Job Title\", \"Student Skills\"]\n",
    "\n",
    "# --- Detect duplicate rows (all members of duplicate groups) ---\n",
    "dup_mask_all = df_sl.duplicated(subset=signal_cols_sl, keep=False)\n",
    "df_sl_dups = df_sl.loc[dup_mask_all].copy()\n",
    "\n",
    "# --- Deduplicate (keep first occurrence) ---\n",
    "df_sl_dedup = df_sl.drop_duplicates(subset=signal_cols_sl, keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "print(\"Original shape:\", df_sl.shape)\n",
    "print(\"Duplicates shape:\", df_sl_dups.shape)\n",
    "print(\"Deduped shape:\", df_sl_dedup.shape)\n",
    "\n",
    "# --- Save results ---\n",
    "output_dir = datasets_folder_path/\"prepared\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_sl_dups.to_csv(datasets_folder_path/\"prepared/srilanka_duplicates.csv\", index=False)\n",
    "df_sl_dedup.to_csv(datasets_folder_path/\"prepared/srilanka_deduped.csv\", index=False)\n",
    "\n",
    "print(\"Files saved in 'processed' folder:\")\n",
    "print(\"- srilanka_duplicates.csv (only duplicate rows)\")\n",
    "print(\"- srilanka_deduped.csv (original minus duplicates)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
